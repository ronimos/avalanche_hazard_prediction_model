# -*- coding: utf-8 -*-
"""
================================================================================
Configuration File for the Avalanche Hazard Forecasting Pipeline
================================================================================

This file centralizes all file paths, API settings, and model parameters
to make the project more modular, maintainable, and easier to configure.

The structure assumes the following project layout:

avalanche_forecasting/
├── data/
│   ├── raw/
│   ├── processed/
│   └── external/
├── models/
├── notebooks/
├── reports/
├── src/
│   └── config.py  <-- This file
└── results/

It is also supports an environment variable `SNOWPACK_DATA_ROOT` to specify a
local path for snowpack data, bypassing the need for downloads on machines
where the data is already available.

Author: Ron Simenhois
"""
import os
import logging
from pathlib import Path

# --- Setup Logging ---
# Configure logging to be used throughout the project.
# This ensures that messages from this config file are captured by the
# logging setup in the main scripts.
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- BASE DIRECTORIES ---
# Assumes this config.py is in the `src` directory.
SRC_DIR = Path(__file__).parent
ROOT_DIR = SRC_DIR.parent

# --- DYNAMIC DATA SOURCE CONFIGURATION ---
# Check for the SNOWPACK_DATA_ROOT environment variable.
# If it exists, use it as the base path for snowpack data.
# Otherwise, default to the local project's data/external/snowpack directory.
SNOWPACK_DATA_ROOT = os.getenv('SNOWPACK_DATA_ROOT')
IS_LOCAL_DATA_SOURCE = SNOWPACK_DATA_ROOT is not None

if IS_LOCAL_DATA_SOURCE:
    logging.info(f"ℹ️ Using local snowpack data source from environment variable: {SNOWPACK_DATA_ROOT}")
    # When using a local source, the path is absolute.
    SNOWPACK_OUTPUT_DIR = Path(SNOWPACK_DATA_ROOT)
else:
    logging.info("ℹ️ No SNOWPACK_DATA_ROOT environment variable found. Defaulting to project's data/external/snowpack directory.")
    # Default behavior: download to the project's local directory.
    SNOWPACK_OUTPUT_DIR = ROOT_DIR / "data" / "external" / "snowpack"


# --- CORE FOLDER STRUCTURE ---
DATA_DIR = ROOT_DIR / "data"
MODELS_DIR = ROOT_DIR / "models"
RESULTS_DIR = ROOT_DIR / "results"
ARTIFACTS_DIR = ROOT_DIR / "artifacts"

# Create directories if they don't exist
DATA_DIR.mkdir(exist_ok=True)
(DATA_DIR / "raw").mkdir(exist_ok=True)
(DATA_DIR / "processed").mkdir(exist_ok=True)
(DATA_DIR / "external").mkdir(exist_ok=True)
SNOWPACK_OUTPUT_DIR.mkdir(exist_ok=True) # Ensure the target snowpack dir exists
MODELS_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)
(RESULTS_DIR / "figures").mkdir(exist_ok=True)
ARTIFACTS_DIR = ROOT_DIR / "artifacts"
ARTIFACTS_DIR.mkdir(exist_ok=True)


# --- FILE PATHS ---
# Central repository for all file paths used across the project.
PATHS = {
    # --- Raw Input Data (should not be modified by scripts) ---
    "RAW_DATA": {
        "polygons": DATA_DIR / "raw" / "BC_Polygons.json",
        "snowpack_locations": DATA_DIR / "raw" / "SnowPackLocations_from_pro_files.csv",
        "danger_ratings": DATA_DIR / "external" / "danger_rating_by_polygon.csv",
    },

    # --- External Data (downloaded from APIs, etc.) ---
    "EXTERNAL_DATA": {
        "raw_avalanche_records": DATA_DIR / "external" / "avalanche_records.json",
        "danger_ratings": DATA_DIR / "raw" / "danger_rating_by_polygon.csv",
        "snowpack_output": SNOWPACK_OUTPUT_DIR, # Use the dynamically set path
    },

    # --- Processed Data (generated by scripts) ---
    "PROCESSED_DATA": {
        "daily_avalanche_data": DATA_DIR / "processed" / "daily_avalanche_data.csv",
        "download_manifest": DATA_DIR / "processed" / "snowpack_download_manifest.csv",
        "training_features": DATA_DIR / "processed" / "training_features.csv",
        "training_targets": DATA_DIR / "processed" / "training_targets.csv",
        "inference_features": DATA_DIR / "processed" / "inference_features.csv",
    },
    
    # --- Model & Analysis Artifacts ---
    "ARTIFACTS": {
        # --- Models, Scalers, Calibrators ---
        "event_model": ARTIFACTS_DIR / "event_model.joblib",
        "event_scaler": ARTIFACTS_DIR / "event_scaler.joblib",
        "hazard_model": ARTIFACTS_DIR / "hazard_model.joblib",
        "hazard_scaler": ARTIFACTS_DIR / "hazard_scaler.joblib",
        "hazard_calibrators": ARTIFACTS_DIR / "hazard_calibrators.joblib",
        
        # --- Feature Lists & Params ---
        "event_final_features": ARTIFACTS_DIR / "event_final_features.json",
        "event_model_params": ARTIFACTS_DIR / "event_model_params.json",
        "hazard_final_features": ARTIFACTS_DIR / "hazard_final_features.json",
        
        # --- Intermediate Predictions ---
        "event_adjusted_predictions": ARTIFACTS_DIR / "event_adjusted_predictions.csv",


        # Avalanche Event Model Artifacts
        "event_predictions": RESULTS_DIR / "avalanche_event_predictions.csv", # Raw predictions
        "event_results_summary": RESULTS_DIR / "avalanche_event_model_performance_summary.csv",
        "event_shap_values": RESULTS_DIR / "avalanche_event_shap_feature_importance.csv",
        "event_feature_names": MODELS_DIR / "avalanche_event_shap_feature_names.csv",
        "all_predictions": RESULTS_DIR / "model_predictions.json",

        # Avalanche Hazard Model Artifacts
        "hazard_model_params": MODELS_DIR / "avalanche_hazard_best_model_params.json",
        "hazard_predictions_csv": RESULTS_DIR / "avalanche_hazard_predictions.csv", # Final hazard predictions
        "hazard_predictions_json": RESULTS_DIR / "avalanche_hazard_predictions.json", # Final hazard predictions
        "hazard_results_summary": RESULTS_DIR / "avalanche_hazard_model_performance_summary.csv",
        "hazard_shap_values": RESULTS_DIR / "avalanche_hazard_shap_feature_importance.csv",
        "hazard_feature_names": MODELS_DIR / "avalanche_hazard_shap_feature_names.csv",
    },
    "RESULTS": {
        # --- Final Predictions & Reports ---
        "hazard_predictions_csv": RESULTS_DIR / "final_hazard_predictions.csv",
        "event_model_report": RESULTS_DIR / "avalanche_event_model_report.json",
        "hazard_model_report": RESULTS_DIR / "avalanche_hazard_model_report.json",

        # --- Plots & Visualizations ---
        "event_pr_curve_plot": RESULTS_DIR / "figures" / "avalanche_event_precision_recall_curve.png",
        "event_shap_plot": RESULTS_DIR / "figures" / "shap_event_importance.png",
        "hazard_shap_plot": RESULTS_DIR / "figures" / "shap_hazard_importance.png",
        "reliability_plot_uncalibrated": RESULTS_DIR / "figures" / "reliability_uncalibrated.png",
        "reliability_plots": RESULTS_DIR / "figures",
        "prediction_map": RESULTS_DIR, # The plot_results script will save maps here by date
        "hazard_confusion_matrix_plot_base": RESULTS_DIR / "figures", # Base path for confusion matrix plots

    },
}


# --- API CONFIGURATION ---
API_CONFIG = {
    "base_url": "https://lb-octonaut.avalanche.dev/api/v2/avalanche_observations",
    "max_pages": 100,
    "page_size": 100,
    "max_retries": 3,
    "retry_delay_sec": 2
}

# --- DATA PROCESSING CONFIGURATION ---
PROCESSING_CONFIG = {
    "target_years": [2023, 2024],
    "geoprojection_epsg": "EPSG:3310",
}

# --- SNOWPACK ANALYSIS CONFIGURATION ---
SNOWPACK_CONFIG = {
    "weak_layer_criteria": {
        'depth': '30 to 100',
        'rc_flat': '< 0.2',
        'density': '< 200',
        'hand_hardness': '< 2',
        'grain_size': '> 1',
        'sphericity': '< 0.25',
        'gs_difference': '> 1',
        'hardness_difference': '>= 1',
        'stress': '> 500',
        'viscosity': '> 1',
        'sn38': '< 0.5',
        'ssi': '< 2',
        'sk38': '< 0.5',
    },
    
    "slab_parameters": {
        'slab_density_mean': ('density', 'mean'),
        'slab_hardness_mean': ('hand_hardness', 'mean'),
        'slab_density_weighted_mean': ('density', 'weighted_mean'),
        'slab_hardness_weighted_mean': ('hand_hardness', 'weighted_mean'),
        'slab_sphericity_mean': ('sphericity', 'mean'),
        'slab_sphericity_weighted_mean': ('sphericity', 'weighted_mean'),
        'slab_log_hardness_mean': lambda df: (2**df['hand_hardness'] * df['thickness']).mean() if not df.empty and 'hand_hardness' in df else None,
        'slab_load': lambda df: (df['thickness'] * df['density']).sum() if not df.empty and 'thickness' in df and 'density' in df else None
    },
    
    "upper_snowpack_parameters": {
        'upper_snowpack_density_mean': ('density', 'mean'),
        'upper_snowpack_sphericity_mean': ('sphericity', 'mean'),
        'upper_snowpack_grain_size_mean': ('grain_size', 'mean'),
        'upper_snowpack_hand_hardness_mean': ('hand_hardness', 'mean'),
    },
}

# --- MODELING CONFIGURATION ---
MODELING_CONFIG = {
    "p_fraction": 0.5,
    "random_state": 42,
}
